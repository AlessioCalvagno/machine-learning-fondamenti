{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32b52aab",
   "metadata": {},
   "source": [
    "# Es 1\n",
    "# Data Preprocessing: Esercitazione\n",
    "\n",
    "Per questo esercizio dovrai pulire e processare il Boston Housing Dataset, un dataset contenente diverse informazioni relative alle abitazione nell'area di Boston. Puoi scaricare il dataset [da qui](https://raw.githubusercontent.com/ProfAI/machine-learning-fondamenti/main/datasets/housing_dirty.csv).\n",
    "\n",
    "Il dataset contiene le seguenti informazioni\n",
    "\n",
    "1. **CRIM** Tasso di criminalità per capita\n",
    "2. **ZN** Percentuale di terreni residenziali suddivisi in zone per lotti superiori a 25.000 sq.ft.\n",
    "3. **INDUS** Percentuale di ettari di attività non al dettaglio per città.\n",
    "4. **CHAS** Variabile dummy che indica la prossimità al fiume Charles.\n",
    "5. **NOX** Concentrazione di ossido d'azoto (parti per 10 milioni).\n",
    "6. **RM** Numero medio di stanze per abitazione\n",
    "7. **AGE** Percentuale di abitazione occupate costruite dopo il 1940\n",
    "8. **DIS** Media pesata delle distanze da 5 centri lavorativi di Boston.\n",
    "9. **RAD** Indice di accessibilità ad autostrade\n",
    "10. **TAX** Aliquota dell'imposta sulla proprietà a valore pieno in 10.000 USD.\n",
    "11. **PRATIO** Rapporto studente-insegnante per città.\n",
    "12. **BLACK** 1000(Bk - 0.63)^2 dove Bk è la percentuale di abitanti di colore per città\n",
    "13. **LSTAT** Percentuale della popolazione povera\n",
    "14. **PRICE** Mediana del valore di abitazioni occupate in 1.000 USD.\n",
    "\n",
    "Nello specifico, devi risolvere i seguenti punti:\n",
    "1. Verifica il numero di righe e colonne del dataset\n",
    "2. Verifica la tipologia di ogni variabile\n",
    "3. Verifica il numero di valori mancanti per ogni colonna\n",
    "4. Rimuovi eventualmente le colonne con oltre il 30% di valori mancanti\n",
    "5. Rimuovi eventualmente le righe con oltre il 25% di valori mancanti\n",
    "6. Rimuovi tutte le righe dove PRICE è mancante\n",
    "7. Esegui l'imputazione con valore medio per i restanti valori mancanti quantitativi\n",
    "8. Esegui la codifica di eventuali variabili qualitative\n",
    "9. Esegui l'imputazione con moda per i restanti valori mancanti qualitativi\n",
    "10. Esegui la standardizzazione\n",
    "11. Salva il nuovo dataframe in un tsv chiamato \"housing_clean.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a753cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>NO</td>\n",
       "      <td>538.0</td>\n",
       "      <td>6575.0</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>NO</td>\n",
       "      <td>469.0</td>\n",
       "      <td>6421.0</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>NO</td>\n",
       "      <td>469.0</td>\n",
       "      <td>7185.0</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>NO</td>\n",
       "      <td>458.0</td>\n",
       "      <td>6998.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>NO</td>\n",
       "      <td>458.0</td>\n",
       "      <td>7147.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CRIM    ZN  INDUS CHAS    NOX      RM   AGE     DIS  RAD    TAX  PTRATIO  \\\n",
       "0.0  LOW  18.0   2.31   NO  538.0  6575.0  65.2  4.0900  1.0  296.0     15.3   \n",
       "1.0  LOW   0.0   7.07   NO  469.0  6421.0  78.9  4.9671  2.0  242.0     17.8   \n",
       "2.0  LOW   0.0   7.07   NO  469.0  7185.0  61.1  4.9671  2.0  242.0     17.8   \n",
       "3.0  LOW   0.0   2.18   NO  458.0  6998.0  45.8  6.0622  3.0  222.0     18.7   \n",
       "4.0  LOW   0.0   2.18   NO  458.0  7147.0  54.2  6.0622  3.0  222.0     18.7   \n",
       "\n",
       "          B  LSTAT  PRICE  \n",
       "0.0  396.90   4.98   24.0  \n",
       "1.0  396.90   9.14   21.6  \n",
       "2.0  392.83   4.03   34.7  \n",
       "3.0  394.63   2.94   33.4  \n",
       "4.0  396.90    NaN   36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "URL_DATASET = \"https://raw.githubusercontent.com/ProfAI/machine-learning-fondamenti/main/datasets/housing_dirty.csv\"\n",
    "\n",
    "dataset = pd.read_csv(URL_DATASET,index_col=0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a097472e",
   "metadata": {},
   "source": [
    "### 1. verifica num colonne e righe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ab7cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9770a15b",
   "metadata": {},
   "source": [
    "### 2. Verifica tipologia delle variabili "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e27bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 506 entries, 0.0 to 505.0\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    object \n",
      " 1   ZN       504 non-null    float64\n",
      " 2   INDUS    503 non-null    float64\n",
      " 3   CHAS     506 non-null    object \n",
      " 4   NOX      499 non-null    float64\n",
      " 5   RM       501 non-null    float64\n",
      " 6   AGE      502 non-null    float64\n",
      " 7   DIS      501 non-null    float64\n",
      " 8   RAD      503 non-null    float64\n",
      " 9   TAX      504 non-null    float64\n",
      " 10  PTRATIO  501 non-null    float64\n",
      " 11  B        503 non-null    float64\n",
      " 12  LSTAT    307 non-null    float64\n",
      " 13  PRICE    502 non-null    float64\n",
      "dtypes: float64(12), object(2)\n",
      "memory usage: 59.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRIM\n",
       "HIGH         130\n",
       "LOW          127\n",
       "VERY HIGH    127\n",
       "MODERATE     122\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#devo fare un typeof? ?_? o è tramite ispezione visiva?\n",
    "#sono tutte quantitative continue, tranne CRIM e CHAS.\n",
    "#CRIM è qualitativa ordinale, CHAS è qualitativa sconnessa.\n",
    "\n",
    "#dalla soluzione:\n",
    "dataset.info() #da info in generale sulle colonne e la tipologia di variabili\n",
    "\n",
    "dataset.describe() #stampa i quartili, media e dev std (delle sole var quantitative)\n",
    "\n",
    "dataset[\"CRIM\"].value_counts() #per le colonne di var qualitative calcola\n",
    "#distribuzione di frequenze assolute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d50f651",
   "metadata": {},
   "source": [
    "### 3. numero di elementi mancanti per ogni colonna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df37f1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM         0\n",
       "ZN           2\n",
       "INDUS        3\n",
       "CHAS         0\n",
       "NOX          7\n",
       "RM           5\n",
       "AGE          4\n",
       "DIS          5\n",
       "RAD          3\n",
       "TAX          2\n",
       "PTRATIO      5\n",
       "B            3\n",
       "LSTAT      199\n",
       "PRICE        4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum() #usando pandas direttamente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c059ba4",
   "metadata": {},
   "source": [
    "### 4. rimuovere colonne con più di 30% di valori mancanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4a28391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354\n",
      "(506, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>NO</td>\n",
       "      <td>538.0</td>\n",
       "      <td>6575.0</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>NO</td>\n",
       "      <td>469.0</td>\n",
       "      <td>6421.0</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>NO</td>\n",
       "      <td>469.0</td>\n",
       "      <td>7185.0</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>NO</td>\n",
       "      <td>458.0</td>\n",
       "      <td>6998.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>NO</td>\n",
       "      <td>458.0</td>\n",
       "      <td>7147.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CRIM    ZN  INDUS CHAS    NOX      RM   AGE     DIS  RAD    TAX  PTRATIO  \\\n",
       "0.0  LOW  18.0   2.31   NO  538.0  6575.0  65.2  4.0900  1.0  296.0     15.3   \n",
       "1.0  LOW   0.0   7.07   NO  469.0  6421.0  78.9  4.9671  2.0  242.0     17.8   \n",
       "2.0  LOW   0.0   7.07   NO  469.0  7185.0  61.1  4.9671  2.0  242.0     17.8   \n",
       "3.0  LOW   0.0   2.18   NO  458.0  6998.0  45.8  6.0622  3.0  222.0     18.7   \n",
       "4.0  LOW   0.0   2.18   NO  458.0  7147.0  54.2  6.0622  3.0  222.0     18.7   \n",
       "\n",
       "          B  PRICE  \n",
       "0.0  396.90   24.0  \n",
       "1.0  396.90   21.6  \n",
       "2.0  392.83   34.7  \n",
       "3.0  394.63   33.4  \n",
       "4.0  396.90   36.2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = int(dataset.shape[0]*0.7) #limite valori validi\n",
    "print(threshold)\n",
    "\n",
    "#help(dataset.dropna)\n",
    "dataset_drop = dataset.copy()\n",
    "dataset_drop.dropna(inplace = True, axis = 1,thresh=threshold)\n",
    "print(dataset_drop.shape)\n",
    "dataset_drop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbf3477",
   "metadata": {},
   "source": [
    "### 5. rimuovere righe con più di 25% valori mancanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "188625be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "(501, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>NO</td>\n",
       "      <td>538.0</td>\n",
       "      <td>6575.0</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>NO</td>\n",
       "      <td>469.0</td>\n",
       "      <td>6421.0</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>NO</td>\n",
       "      <td>469.0</td>\n",
       "      <td>7185.0</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>NO</td>\n",
       "      <td>458.0</td>\n",
       "      <td>6998.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>NO</td>\n",
       "      <td>458.0</td>\n",
       "      <td>7147.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CRIM    ZN  INDUS CHAS    NOX      RM   AGE     DIS  RAD    TAX  PTRATIO  \\\n",
       "0.0  LOW  18.0   2.31   NO  538.0  6575.0  65.2  4.0900  1.0  296.0     15.3   \n",
       "1.0  LOW   0.0   7.07   NO  469.0  6421.0  78.9  4.9671  2.0  242.0     17.8   \n",
       "2.0  LOW   0.0   7.07   NO  469.0  7185.0  61.1  4.9671  2.0  242.0     17.8   \n",
       "3.0  LOW   0.0   2.18   NO  458.0  6998.0  45.8  6.0622  3.0  222.0     18.7   \n",
       "4.0  LOW   0.0   2.18   NO  458.0  7147.0  54.2  6.0622  3.0  222.0     18.7   \n",
       "\n",
       "          B  PRICE  \n",
       "0.0  396.90   24.0  \n",
       "1.0  396.90   21.6  \n",
       "2.0  392.83   34.7  \n",
       "3.0  394.63   33.4  \n",
       "4.0  396.90   36.2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold2 = int(dataset.shape[1]*0.75) #limite valori validi\n",
    "print(threshold2)\n",
    "\n",
    "dataset_drop.dropna(inplace = True, axis = 0,thresh=threshold2)\n",
    "print(dataset_drop.shape)\n",
    "dataset_drop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef732e0f",
   "metadata": {},
   "source": [
    "### 6. rimuovi righe dove PRICE è mancante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35664951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(497, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>NO</td>\n",
       "      <td>538.0</td>\n",
       "      <td>6575.0</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>NO</td>\n",
       "      <td>469.0</td>\n",
       "      <td>6421.0</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>NO</td>\n",
       "      <td>469.0</td>\n",
       "      <td>7185.0</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>NO</td>\n",
       "      <td>458.0</td>\n",
       "      <td>6998.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>NO</td>\n",
       "      <td>458.0</td>\n",
       "      <td>7147.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CRIM    ZN  INDUS CHAS    NOX      RM   AGE     DIS  RAD    TAX  PTRATIO  \\\n",
       "0.0  LOW  18.0   2.31   NO  538.0  6575.0  65.2  4.0900  1.0  296.0     15.3   \n",
       "1.0  LOW   0.0   7.07   NO  469.0  6421.0  78.9  4.9671  2.0  242.0     17.8   \n",
       "2.0  LOW   0.0   7.07   NO  469.0  7185.0  61.1  4.9671  2.0  242.0     17.8   \n",
       "3.0  LOW   0.0   2.18   NO  458.0  6998.0  45.8  6.0622  3.0  222.0     18.7   \n",
       "4.0  LOW   0.0   2.18   NO  458.0  7147.0  54.2  6.0622  3.0  222.0     18.7   \n",
       "\n",
       "          B  PRICE  \n",
       "0.0  396.90   24.0  \n",
       "1.0  396.90   21.6  \n",
       "2.0  392.83   34.7  \n",
       "3.0  394.63   33.4  \n",
       "4.0  396.90   36.2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#help(dataset.dropna)\n",
    "\n",
    "dataset_drop_price = dataset_drop.copy()\n",
    "\n",
    "dataset_drop_price.dropna(inplace = True, axis = 0, subset=[\"PRICE\"])\n",
    "\n",
    "print(dataset_drop_price.shape)\n",
    "dataset_drop_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a60fa46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      1\n",
       "CHAS       0\n",
       "NOX        4\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        1\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    3\n",
       "B          1\n",
       "PRICE      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verifica\n",
    "dataset_drop_price.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93b14c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      1\n",
       "CHAS       0\n",
       "NOX        4\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        1\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    3\n",
       "B          1\n",
       "PRICE      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_drop.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dac6f9f",
   "metadata": {},
   "source": [
    "### 7. Esegui l'imputazione con valore medio per i restanti valori mancanti quantitativi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f41a547a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18.  ,   2.31, 538.  , ...,  15.3 , 396.9 ,  24.  ],\n",
       "       [  0.  ,   7.07, 469.  , ...,  17.8 , 396.9 ,  21.6 ],\n",
       "       [  0.  ,   7.07, 469.  , ...,  17.8 , 392.83,  34.7 ],\n",
       "       ...,\n",
       "       [  0.  ,  11.93, 573.  , ...,  21.  , 396.9 ,  23.9 ],\n",
       "       [  0.  ,  11.93, 573.  , ...,  21.  , 393.45,  22.  ],\n",
       "       [  0.  ,  11.93, 573.  , ...,  21.  , 396.9 ,  11.9 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uso scikit learn e il transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "dataset_clean = dataset_drop_price.copy()\n",
    "\n",
    "dataset_clean_num = dataset_clean.select_dtypes(include=['number'])\n",
    "\n",
    "dataset_clean_num.head()\n",
    "\n",
    "si = SimpleImputer(strategy = \"mean\", copy = False)\n",
    "\n",
    "si.fit_transform(dataset_clean_num)\n",
    "\n",
    "#dataset_clean_num.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dce3ca",
   "metadata": {},
   "source": [
    "### 8. Esegui la codifica di eventuali variabili qualitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9514e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>NO</td>\n",
       "      <td>538.0</td>\n",
       "      <td>6575.0</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>NO</td>\n",
       "      <td>469.0</td>\n",
       "      <td>6421.0</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>NO</td>\n",
       "      <td>469.0</td>\n",
       "      <td>7185.0</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>NO</td>\n",
       "      <td>458.0</td>\n",
       "      <td>6998.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>LOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>NO</td>\n",
       "      <td>458.0</td>\n",
       "      <td>7147.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CRIM    ZN  INDUS CHAS    NOX      RM   AGE     DIS  RAD    TAX  PTRATIO  \\\n",
       "0.0  LOW  18.0   2.31   NO  538.0  6575.0  65.2  4.0900  1.0  296.0     15.3   \n",
       "1.0  LOW   0.0   7.07   NO  469.0  6421.0  78.9  4.9671  2.0  242.0     17.8   \n",
       "2.0  LOW   0.0   7.07   NO  469.0  7185.0  61.1  4.9671  2.0  242.0     17.8   \n",
       "3.0  LOW   0.0   2.18   NO  458.0  6998.0  45.8  6.0622  3.0  222.0     18.7   \n",
       "4.0  LOW   0.0   2.18   NO  458.0  7147.0  54.2  6.0622  3.0  222.0     18.7   \n",
       "\n",
       "          B  PRICE  \n",
       "0.0  396.90   24.0  \n",
       "1.0  396.90   21.6  \n",
       "2.0  392.83   34.7  \n",
       "3.0  394.63   33.4  \n",
       "4.0  396.90   36.2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#riporto tutto alla variabile dataset_clean\n",
    "dataset_clean=pd.concat([dataset_clean.iloc[:,0],\n",
    "                         dataset_clean_num.iloc[:,[0,1]],dataset_clean[\"CHAS\"],dataset_clean_num.iloc[:,2:]],axis=1)\n",
    "#verifica\n",
    "dataset_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1059c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dataset_clean.isna().sum()\n",
    "\n",
    "#ok procedi\n",
    "\n",
    "#uso mapping per variabili qualitative ordinali\n",
    "mapping = {\"LOW\":1, \"MODERATE\":2, \"HIGH\":3, \"VERY HIGH\":4} \n",
    "dataset_clean[\"CRIM\"] = dataset_clean[\"CRIM\"].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2504a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>NO</td>\n",
       "      <td>538.0</td>\n",
       "      <td>6575.0</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>NO</td>\n",
       "      <td>469.0</td>\n",
       "      <td>6421.0</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>NO</td>\n",
       "      <td>469.0</td>\n",
       "      <td>7185.0</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>NO</td>\n",
       "      <td>458.0</td>\n",
       "      <td>6998.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>NO</td>\n",
       "      <td>458.0</td>\n",
       "      <td>7147.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CRIM    ZN  INDUS CHAS    NOX      RM   AGE     DIS  RAD    TAX  PTRATIO  \\\n",
       "0.0     1  18.0   2.31   NO  538.0  6575.0  65.2  4.0900  1.0  296.0     15.3   \n",
       "1.0     1   0.0   7.07   NO  469.0  6421.0  78.9  4.9671  2.0  242.0     17.8   \n",
       "2.0     1   0.0   7.07   NO  469.0  7185.0  61.1  4.9671  2.0  242.0     17.8   \n",
       "3.0     1   0.0   2.18   NO  458.0  6998.0  45.8  6.0622  3.0  222.0     18.7   \n",
       "4.0     1   0.0   2.18   NO  458.0  7147.0  54.2  6.0622  3.0  222.0     18.7   \n",
       "\n",
       "          B  PRICE  \n",
       "0.0  396.90   24.0  \n",
       "1.0  396.90   21.6  \n",
       "2.0  392.83   34.7  \n",
       "3.0  394.63   33.4  \n",
       "4.0  396.90   36.2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_clean.head()\n",
    "\n",
    "#print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4800ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uso LabelEncoder per variabili qualitative sconnesse\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "dataset_clean[\"CHAS\"] = le.fit_transform(dataset_clean[\"CHAS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4df03a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "PRICE      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_clean.head()\n",
    "dataset_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea098b22",
   "metadata": {},
   "source": [
    "### 9. Esegui l'imputazione con moda per i restanti valori mancanti qualitativi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ecd1489",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ma in realtà non ne restano\n",
    "\n",
    "#qualora ci fossero posso usare di nuovo il metodo del SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6939e4",
   "metadata": {},
   "source": [
    " ### 10. Esegui la standardizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86ad1af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uso sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "#in output si ottiene array np e non dataframe\n",
    "dataset_clean_np = ss.fit_transform(dataset_clean) \n",
    "\n",
    "#per mantenere dataframe uso la formula diretta\n",
    "dataset_clean = (dataset_clean - dataset_clean.mean())/dataset_clean.std(ddof=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db1cedb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class StandardScaler in module sklearn.preprocessing._data:\n",
      "\n",
      "class StandardScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      " |  StandardScaler(*, copy=True, with_mean=True, with_std=True)\n",
      " |  \n",
      " |  Standardize features by removing the mean and scaling to unit variance.\n",
      " |  \n",
      " |  The standard score of a sample `x` is calculated as:\n",
      " |  \n",
      " |      z = (x - u) / s\n",
      " |  \n",
      " |  where `u` is the mean of the training samples or zero if `with_mean=False`,\n",
      " |  and `s` is the standard deviation of the training samples or one if\n",
      " |  `with_std=False`.\n",
      " |  \n",
      " |  Centering and scaling happen independently on each feature by computing\n",
      " |  the relevant statistics on the samples in the training set. Mean and\n",
      " |  standard deviation are then stored to be used on later data using\n",
      " |  :meth:`transform`.\n",
      " |  \n",
      " |  Standardization of a dataset is a common requirement for many\n",
      " |  machine learning estimators: they might behave badly if the\n",
      " |  individual features do not more or less look like standard normally\n",
      " |  distributed data (e.g. Gaussian with 0 mean and unit variance).\n",
      " |  \n",
      " |  For instance many elements used in the objective function of\n",
      " |  a learning algorithm (such as the RBF kernel of Support Vector\n",
      " |  Machines or the L1 and L2 regularizers of linear models) assume that\n",
      " |  all features are centered around 0 and have variance in the same\n",
      " |  order. If a feature has a variance that is orders of magnitude larger\n",
      " |  than others, it might dominate the objective function and make the\n",
      " |  estimator unable to learn from other features correctly as expected.\n",
      " |  \n",
      " |  This scaler can also be applied to sparse CSR or CSC matrices by passing\n",
      " |  `with_mean=False` to avoid breaking the sparsity structure of the data.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  copy : bool, default=True\n",
      " |      If False, try to avoid a copy and do inplace scaling instead.\n",
      " |      This is not guaranteed to always work inplace; e.g. if the data is\n",
      " |      not a NumPy array or scipy.sparse CSR matrix, a copy may still be\n",
      " |      returned.\n",
      " |  \n",
      " |  with_mean : bool, default=True\n",
      " |      If True, center the data before scaling.\n",
      " |      This does not work (and will raise an exception) when attempted on\n",
      " |      sparse matrices, because centering them entails building a dense\n",
      " |      matrix which in common use cases is likely to be too large to fit in\n",
      " |      memory.\n",
      " |  \n",
      " |  with_std : bool, default=True\n",
      " |      If True, scale the data to unit variance (or equivalently,\n",
      " |      unit standard deviation).\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  scale_ : ndarray of shape (n_features,) or None\n",
      " |      Per feature relative scaling of the data to achieve zero mean and unit\n",
      " |      variance. Generally this is calculated using `np.sqrt(var_)`. If a\n",
      " |      variance is zero, we can't achieve unit variance, and the data is left\n",
      " |      as-is, giving a scaling factor of 1. `scale_` is equal to `None`\n",
      " |      when `with_std=False`.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *scale_*\n",
      " |  \n",
      " |  mean_ : ndarray of shape (n_features,) or None\n",
      " |      The mean value for each feature in the training set.\n",
      " |      Equal to ``None`` when ``with_mean=False``.\n",
      " |  \n",
      " |  var_ : ndarray of shape (n_features,) or None\n",
      " |      The variance for each feature in the training set. Used to compute\n",
      " |      `scale_`. Equal to ``None`` when ``with_std=False``.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_samples_seen_ : int or ndarray of shape (n_features,)\n",
      " |      The number of samples processed by the estimator for each feature.\n",
      " |      If there are no missing samples, the ``n_samples_seen`` will be an\n",
      " |      integer, otherwise it will be an array of dtype int. If\n",
      " |      `sample_weights` are used it will be a float (if no missing data)\n",
      " |      or an array of dtype float that sums the weights seen so far.\n",
      " |      Will be reset on new calls to fit, but increments across\n",
      " |      ``partial_fit`` calls.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  scale : Equivalent function without the estimator API.\n",
      " |  \n",
      " |  :class:`~sklearn.decomposition.PCA` : Further removes the linear\n",
      " |      correlation across features with 'whiten=True'.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  NaNs are treated as missing values: disregarded in fit, and maintained in\n",
      " |  transform.\n",
      " |  \n",
      " |  We use a biased estimator for the standard deviation, equivalent to\n",
      " |  `numpy.std(x, ddof=0)`. Note that the choice of `ddof` is unlikely to\n",
      " |  affect model performance.\n",
      " |  \n",
      " |  For a comparison of the different scalers, transformers, and normalizers,\n",
      " |  see :ref:`examples/preprocessing/plot_all_scaling.py\n",
      " |  <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
      " |  >>> scaler = StandardScaler()\n",
      " |  >>> print(scaler.fit(data))\n",
      " |  StandardScaler()\n",
      " |  >>> print(scaler.mean_)\n",
      " |  [0.5 0.5]\n",
      " |  >>> print(scaler.transform(data))\n",
      " |  [[-1. -1.]\n",
      " |   [-1. -1.]\n",
      " |   [ 1.  1.]\n",
      " |   [ 1.  1.]]\n",
      " |  >>> print(scaler.transform([[2, 2]]))\n",
      " |  [[3. 3.]]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      StandardScaler\n",
      " |      sklearn.base.OneToOneFeatureMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.utils._set_output._SetOutputMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, copy=True, with_mean=True, with_std=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None, sample_weight=None)\n",
      " |      Compute the mean and std to be used for later scaling.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data used to compute the mean and standard deviation\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y : None\n",
      " |          Ignored.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Individual weights for each sample.\n",
      " |      \n",
      " |          .. versionadded:: 0.24\n",
      " |             parameter *sample_weight* support to StandardScaler.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted scaler.\n",
      " |  \n",
      " |  inverse_transform(self, X, copy=None)\n",
      " |      Scale back the data to the original representation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data used to scale along the features axis.\n",
      " |      copy : bool, default=None\n",
      " |          Copy the input X or not.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  partial_fit(self, X, y=None, sample_weight=None)\n",
      " |      Online computation of mean and std on X for later scaling.\n",
      " |      \n",
      " |      All of X is processed as a single batch. This is intended for cases\n",
      " |      when :meth:`fit` is not feasible due to very large number of\n",
      " |      `n_samples` or because X is read from a continuous stream.\n",
      " |      \n",
      " |      The algorithm for incremental mean and std is given in Equation 1.5a,b\n",
      " |      in Chan, Tony F., Gene H. Golub, and Randall J. LeVeque. \"Algorithms\n",
      " |      for computing the sample variance: Analysis and recommendations.\"\n",
      " |      The American Statistician 37.3 (1983): 242-247:\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data used to compute the mean and standard deviation\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y : None\n",
      " |          Ignored.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Individual weights for each sample.\n",
      " |      \n",
      " |          .. versionadded:: 0.24\n",
      " |             parameter *sample_weight* support to StandardScaler.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted scaler.\n",
      " |  \n",
      " |  set_fit_request(self: sklearn.preprocessing._data.StandardScaler, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.StandardScaler\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_inverse_transform_request(self: sklearn.preprocessing._data.StandardScaler, *, copy: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.StandardScaler\n",
      " |      Request metadata passed to the ``inverse_transform`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``inverse_transform`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``inverse_transform``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``copy`` parameter in ``inverse_transform``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_partial_fit_request(self: sklearn.preprocessing._data.StandardScaler, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.StandardScaler\n",
      " |      Request metadata passed to the ``partial_fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``partial_fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_transform_request(self: sklearn.preprocessing._data.StandardScaler, *, copy: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.StandardScaler\n",
      " |      Request metadata passed to the ``transform`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``transform`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``transform``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``copy`` parameter in ``transform``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  transform(self, X, copy=None)\n",
      " |      Perform standardization by centering and scaling.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix of shape (n_samples, n_features)\n",
      " |          The data used to scale along the features axis.\n",
      " |      copy : bool, default=None\n",
      " |          Copy the input X or not.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.OneToOneFeatureMixin:\n",
      " |  \n",
      " |  get_feature_names_out(self, input_features=None)\n",
      " |      Get output feature names for transformation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_features : array-like of str or None, default=None\n",
      " |          Input features.\n",
      " |      \n",
      " |          - If `input_features` is `None`, then `feature_names_in_` is\n",
      " |            used as feature names in. If `feature_names_in_` is not defined,\n",
      " |            then the following input feature names are generated:\n",
      " |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      " |          - If `input_features` is an array-like, then `input_features` must\n",
      " |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_names_out : ndarray of str objects\n",
      " |          Same as input features.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.OneToOneFeatureMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      " |      and returns a transformed version of `X`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input samples.\n",
      " |      \n",
      " |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      " |          Target values (None for unsupervised transformations).\n",
      " |      \n",
      " |      **fit_params : dict\n",
      " |          Additional fit parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |  \n",
      " |  set_output(self, *, transform=None)\n",
      " |      Set output container.\n",
      " |      \n",
      " |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      " |      for an example on how to use the API.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      transform : {\"default\", \"pandas\"}, default=None\n",
      " |          Configure output of `transform` and `fit_transform`.\n",
      " |      \n",
      " |          - `\"default\"`: Default output format of a transformer\n",
      " |          - `\"pandas\"`: DataFrame output\n",
      " |          - `None`: Transform configuration is unchanged\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |  \n",
      " |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08c20f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>-1.33359</td>\n",
       "      <td>0.276292</td>\n",
       "      <td>-1.287892</td>\n",
       "      <td>-0.270987</td>\n",
       "      <td>0.334165</td>\n",
       "      <td>0.471869</td>\n",
       "      <td>-0.114472</td>\n",
       "      <td>-0.297837</td>\n",
       "      <td>-0.984211</td>\n",
       "      <td>-0.669687</td>\n",
       "      <td>-1.476303</td>\n",
       "      <td>0.439287</td>\n",
       "      <td>0.164096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>-1.33359</td>\n",
       "      <td>-0.491081</td>\n",
       "      <td>-0.594897</td>\n",
       "      <td>-0.270987</td>\n",
       "      <td>0.025587</td>\n",
       "      <td>0.395235</td>\n",
       "      <td>0.370547</td>\n",
       "      <td>-0.297150</td>\n",
       "      <td>-0.870030</td>\n",
       "      <td>-0.988387</td>\n",
       "      <td>-0.311669</td>\n",
       "      <td>0.439287</td>\n",
       "      <td>-0.097371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>-1.33359</td>\n",
       "      <td>-0.491081</td>\n",
       "      <td>-0.594897</td>\n",
       "      <td>-0.270987</td>\n",
       "      <td>0.025587</td>\n",
       "      <td>0.775421</td>\n",
       "      <td>-0.259623</td>\n",
       "      <td>-0.297150</td>\n",
       "      <td>-0.870030</td>\n",
       "      <td>-0.988387</td>\n",
       "      <td>-0.311669</td>\n",
       "      <td>0.394882</td>\n",
       "      <td>1.329804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>-1.33359</td>\n",
       "      <td>-0.491081</td>\n",
       "      <td>-1.306818</td>\n",
       "      <td>-0.270987</td>\n",
       "      <td>-0.023607</td>\n",
       "      <td>0.682365</td>\n",
       "      <td>-0.801287</td>\n",
       "      <td>-0.296293</td>\n",
       "      <td>-0.755849</td>\n",
       "      <td>-1.106424</td>\n",
       "      <td>0.107599</td>\n",
       "      <td>0.414520</td>\n",
       "      <td>1.188176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>-1.33359</td>\n",
       "      <td>-0.491081</td>\n",
       "      <td>-1.306818</td>\n",
       "      <td>-0.270987</td>\n",
       "      <td>-0.023607</td>\n",
       "      <td>0.756511</td>\n",
       "      <td>-0.503903</td>\n",
       "      <td>-0.296293</td>\n",
       "      <td>-0.755849</td>\n",
       "      <td>-1.106424</td>\n",
       "      <td>0.107599</td>\n",
       "      <td>0.439287</td>\n",
       "      <td>1.493221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0.0 -1.33359  0.276292 -1.287892 -0.270987  0.334165  0.471869 -0.114472   \n",
       "1.0 -1.33359 -0.491081 -0.594897 -0.270987  0.025587  0.395235  0.370547   \n",
       "2.0 -1.33359 -0.491081 -0.594897 -0.270987  0.025587  0.775421 -0.259623   \n",
       "3.0 -1.33359 -0.491081 -1.306818 -0.270987 -0.023607  0.682365 -0.801287   \n",
       "4.0 -1.33359 -0.491081 -1.306818 -0.270987 -0.023607  0.756511 -0.503903   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     PRICE  \n",
       "0.0 -0.297837 -0.984211 -0.669687 -1.476303  0.439287  0.164096  \n",
       "1.0 -0.297150 -0.870030 -0.988387 -0.311669  0.439287 -0.097371  \n",
       "2.0 -0.297150 -0.870030 -0.988387 -0.311669  0.394882  1.329804  \n",
       "3.0 -0.296293 -0.755849 -1.106424  0.107599  0.414520  1.188176  \n",
       "4.0 -0.296293 -0.755849 -1.106424  0.107599  0.439287  1.493221  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset_clean)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe605d1",
   "metadata": {},
   "source": [
    "### 11. Salva il nuovo dataframe in un tsv chiamato \"housing_cleaned.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8279a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean.to_csv(\"data set es 1 clean.tsv\",sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
